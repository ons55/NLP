{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sent2vec.vectorizer import Vectorizer\n",
    "from scipy import spatial\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(sentence):\n",
    "    # convert to lowercase, ignore all special characters - keep only\n",
    "    # alpha-numericals and spaces\n",
    "    sentence = re.sub(r'[^A-Za-z0-9\\s]', r'', str(sentence).lower())\n",
    "    #Removing stop_words\n",
    "    f= open(\"stop_words.txt\",\"r\")\n",
    "    stopwords=[]\n",
    "    for line in f:\n",
    "        word=line.strip()\n",
    "        stopwords.append(word)\n",
    "    sentence = \" \".join([word for word in sentence.split()\n",
    "                        if word not in stopwords])\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(sent1,sent2):\n",
    "    \n",
    "    #Cleaning Data\n",
    "    sent1=cleanData(sent1)\n",
    "    sent2=cleanData(sent2)\n",
    "    sentences=[sent1,sent2]\n",
    "    # Sentence embedding Bert\n",
    "    vectorizer = Vectorizer()\n",
    "    vectorizer.bert(sentences)\n",
    "    vectors = vectorizer.vectors\n",
    "    v1=vectors[0]\n",
    "    v2=vectors[1]\n",
    "    sim=1 - spatial.distance.cosine(v1, v2)\n",
    "\n",
    "    \n",
    "    return sim\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(query,data):\n",
    "    \n",
    "    file1=open(query, \"r\")\n",
    "    file2=open(data, \"r\")\n",
    "    lines = file2.readlines()\n",
    "    sent1=file1.readlines()\n",
    "    list_sim=[]\n",
    "    for line in lines:\n",
    "        sent2=line.strip()\n",
    "        sim=similarity(sent1,sent2)\n",
    "        list_sim.append(sim)\n",
    "    \n",
    "    result=dict(zip(lines,list_sim))\n",
    "    sorted_result=dict(sorted(result.items(), key=lambda x: x[1],reverse=True))\n",
    "    list_result=list(sorted_result.keys())\n",
    "    return list_result[0],list_result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Our hearts and prayers are with all of the communities and businesses who are struggling to survive in the midst of this public health and economic crisis.\\n',\n",
       " 'If the past few hours are any indication, the next month could look bleak for restaurateurs dealing with the severe restrictions put in place by Gov.\\n')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(\"query.txt\",\"data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
